{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Download packages\n"
      ],
      "metadata": {
        "id": "IdRt77gC2f5U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyAOSo8sOoA9",
        "outputId": "9d658a2e-7554-49cb-a9b7-584ad21c4070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.14)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "This nsubj\n",
            "is ROOT\n",
            "her poss\n",
            "book attr\n",
            ". punct\n",
            "\n",
            "Give ROOT\n",
            "the det\n",
            "book dobj\n",
            "back advmod\n",
            "to prep\n",
            "her pobj\n",
            ". punct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! pip install spacy\n",
        "! python -m spacy download en_core_web_sm\n",
        "\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "text = [\n",
        "    \"This is her book.\",\n",
        "    \"Give the book back to her.\"\n",
        "]\n",
        "\n",
        "\n",
        "for t in text:\n",
        "    doc = nlp(t)\n",
        "\n",
        "    for tok in doc:\n",
        "        print(tok.text, tok.dep_)\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part1**"
      ],
      "metadata": {
        "id": "J084iM9eQB0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy torch==2.0.1 torchtext==0.15.2 nltk scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.vocab import GloVe\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCKQQGblOqt0",
        "outputId": "a5a2419b-df29-4d45-9852-8c5b4e16f89e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "Requirement already satisfied: torchtext==0.15.2 in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (2.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (0.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.5.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (18.1.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (2025.7.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
        "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})"
      ],
      "metadata": {
        "id": "3W1M_W8uQNGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = tokenizer(text.lower())\n",
        "    return [t for t in tokens if t not in stop_words]\n",
        "\n",
        "df['tokens'] = df['review'].apply(tokenize)"
      ],
      "metadata": {
        "id": "slB_VjhWQe8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import torch\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "# Assuming df['tokens'] is a column of tokenized lists\n",
        "counter = Counter()\n",
        "for tokens in df['tokens']:\n",
        "    counter.update(tokens)\n",
        "\n",
        "# Use `vocab(...)` directly — no need for torchtext.vocab.vocab\n",
        "vocab_obj = vocab(counter, specials=[\"<unk>\", \"<pad>\"])\n",
        "vocab_obj.set_default_index(vocab_obj[\"<unk>\"])\n",
        "\n",
        "# Example usage\n",
        "print(vocab_obj[\"<pad>\"])\n",
        "print(vocab_obj[\"some_word\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCOSvMaCQe_7",
        "outputId": "b04ff406-4232-4234-db41-80d2e5f66790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Numericalize function\n",
        "def numericalize(tokens):\n",
        "    return [vocab_obj[token] for token in tokens]\n",
        "\n",
        "df['numerical'] = df['tokens'].apply(numericalize)\n",
        "\n",
        "# Pad sequences\n",
        "MAX_LEN = 300\n",
        "\n",
        "def pad_input(seq):\n",
        "    seq = seq[:MAX_LEN]\n",
        "    return torch.tensor(seq + [vocab_obj[\"<pad>\"]] * (MAX_LEN - len(seq)))\n",
        "\n",
        "df['padded'] = df['numerical'].apply(pad_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YByHkOwMQfCz",
        "outputId": "95f3cb3a-c94e-4e4d-a2f3-f357435eb554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-10-82445146.py\", line 14, in <cell line: 0>\n",
            "    df['padded'] = df['numerical'].apply(pad_input)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\", line 4924, in apply\n",
            "    ).apply()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\", line 1427, in apply\n",
            "    return self.apply_standard()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\", line 1507, in apply_standard\n",
            "    mapped = obj._map_values(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/base.py\", line 921, in _map_values\n",
            "    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py\", line 1743, in map_array\n",
            "    return lib.map_infer(values, mapper, convert=convert)\n",
            "  File \"/tmp/ipython-input-10-82445146.py\", line 12, in pad_input\n",
            "    return torch.tensor(seq + [vocab_obj[\"<pad>\"]] * (MAX_LEN - len(seq)))\n",
            "/tmp/ipython-input-10-82445146.py:12: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  return torch.tensor(seq + [vocab_obj[\"<pad>\"]] * (MAX_LEN - len(seq)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Inputs\n",
        "X = torch.stack(df['padded'].tolist())\n",
        "y = torch.tensor(df['sentiment'].tolist(), dtype=torch.long)\n",
        "\n",
        "# Convert to list for train_test_split\n",
        "X_list = X.tolist()\n",
        "y_list = y.tolist()\n",
        "\n",
        "# Train-test split\n",
        "X_train_list, X_test_list, y_train_list, y_test_list = train_test_split(X_list, y_list, test_size=0.2)\n",
        "\n",
        "# Convert back to tensors\n",
        "X_train = torch.tensor(X_train_list, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test_list, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train_list, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test_list, dtype=torch.long)\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "2aIuwyQKQfFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, embedding_matrix):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        embedding_dim = embedding_matrix.shape[1]\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=128, batch_first=True)\n",
        "        self.fc = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)                           # [batch_size, seq_len, emb_dim]\n",
        "        output, hidden = self.rnn(embedded)                    # hidden: [1, batch_size, hidden_dim]\n",
        "        out = self.fc(hidden.squeeze(0))                       # [batch_size, 1]\n",
        "        return torch.sigmoid(out).squeeze(1)                   # [batch_size]"
      ],
      "metadata": {
        "id": "WXRckY39RLMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, embedding_matrix):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        embedding_dim = embedding_matrix.shape[1]  # safer than hardcoding 100\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=128, batch_first=True)\n",
        "        self.fc = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)                      # [batch_size, seq_len, emb_dim]\n",
        "        _, (hidden, _) = self.lstm(embedded)              # hidden: [1, batch_size, 128]\n",
        "        out = self.fc(hidden.squeeze(0))                  # [batch_size, 1]\n",
        "        return torch.sigmoid(out).squeeze(1)              # [batch_size]"
      ],
      "metadata": {
        "id": "fd7m-_QxRLPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_model(model, loader, epochs=5):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device).float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(xb)  # shape: [batch_size]\n",
        "            loss = criterion(outputs, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy during training (optional)\n",
        "            preds = (outputs >= 0.5).float()\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        accuracy = correct / total * 100\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f} | Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "YGH4jFoKRLSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device).float()  # Ensure yb is float for comparison\n",
        "            outputs = model(xb)\n",
        "            preds = (outputs >= 0.5).float()\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "j62y5La4RLUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------\n",
        "# Device configuration\n",
        "# -------------------------\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# -------------------------\n",
        "# Dummy data (replace with real data)\n",
        "# -------------------------\n",
        "# Assume each input sequence is 100-dimensional and of length 50\n",
        "vocab_size = 5000\n",
        "embedding_dim = 100\n",
        "sequence_length = 50\n",
        "num_samples = 1000\n",
        "\n",
        "X = torch.randint(0, vocab_size, (num_samples, sequence_length))\n",
        "y = torch.randint(0, 2, (num_samples,)).float()\n",
        "\n",
        "# -------------------------\n",
        "# Embedding matrix (random for demo)\n",
        "# Replace with pretrained like GloVe if available\n",
        "# -------------------------\n",
        "embedding_matrix = torch.randn(vocab_size, embedding_dim)\n",
        "\n",
        "# -------------------------\n",
        "# Dataset and DataLoader\n",
        "# -------------------------\n",
        "dataset = TensorDataset(X, y)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# -------------------------\n",
        "# Model Definitions\n",
        "# -------------------------\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, embedding_matrix):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        self.rnn = nn.RNN(embedding_dim, 128, batch_first=True)\n",
        "        self.fc = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        return torch.sigmoid(self.fc(hidden.squeeze(0)))\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, embedding_matrix):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        self.lstm = nn.LSTM(embedding_dim, 128, batch_first=True)\n",
        "        self.fc = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        _, (hidden, _) = self.lstm(embedded)\n",
        "        return torch.sigmoid(self.fc(hidden.squeeze(0)))\n",
        "\n",
        "# -------------------------\n",
        "# Training function\n",
        "# -------------------------\n",
        "def train_model(model, loader, epochs=5):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device).float()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(xb).squeeze()\n",
        "            loss = criterion(outputs, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader):.4f}\")\n",
        "\n",
        "# -------------------------\n",
        "# Evaluation function\n",
        "# -------------------------\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device).float()\n",
        "            preds = (model(xb).squeeze() > 0.5).float()\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "    accuracy = 100 * correct / total if total != 0 else 0\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# -------------------------\n",
        "# Run RNN\n",
        "# -------------------------\n",
        "print(\"Training RNN...\")\n",
        "rnn_model = RNNClassifier(embedding_matrix)\n",
        "train_model(rnn_model, train_loader)\n",
        "evaluate(rnn_model, test_loader)\n",
        "\n",
        "# -------------------------\n",
        "# Run LSTM\n",
        "# -------------------------\n",
        "print(\"\\nTraining LSTM...\")\n",
        "lstm_model = LSTMClassifier(embedding_matrix)\n",
        "train_model(lstm_model, train_loader)\n",
        "evaluate(lstm_model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzi4_vsBRauV",
        "outputId": "2bf55bd3-1010-4d62-82bf-325a75f6b122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RNN...\n",
            "Epoch 1, Loss: 0.7032\n",
            "Epoch 2, Loss: 0.6154\n",
            "Epoch 3, Loss: 0.4966\n",
            "Epoch 4, Loss: 0.3175\n",
            "Epoch 5, Loss: 0.1441\n",
            "Accuracy: 49.00%\n",
            "\n",
            "Training LSTM...\n",
            "Epoch 1, Loss: 0.6913\n",
            "Epoch 2, Loss: 0.6488\n",
            "Epoch 3, Loss: 0.5712\n",
            "Epoch 4, Loss: 0.4147\n",
            "Epoch 5, Loss: 0.2134\n",
            "Accuracy: 53.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part2**"
      ],
      "metadata": {
        "id": "AsSm5OCXWLLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import csv\n",
        "\n",
        "# Month name to number mapping\n",
        "MONTHS = {\n",
        "    'january': '01', 'february': '02', 'march': '03', 'april': '04',\n",
        "    'may': '05', 'june': '06', 'july': '07', 'august': '08',\n",
        "    'september': '09', 'october': '10', 'november': '11', 'december': '12'\n",
        "}\n",
        "\n",
        "# Regex patterns for different date formats\n",
        "DATE_PATTERNS = [\n",
        "    r'(\\d{1,2})(st|nd|rd|th)?\\s+(January|February|March|April|May|June|July|August|September|October|November|December)[,]?\\s+(\\d{4})',\n",
        "    r'(January|February|March|April|May|June|July|August|September|October|November|December)\\s+(\\d{1,2})(st|nd|rd|th)?[,]?\\s+(\\d{4})',\n",
        "    r'(\\d{1,2})/(\\d{1,2})/(\\d{4})',\n",
        "    r'(\\d{1,2})-(\\d{1,2})-(\\d{4})'\n",
        "]\n",
        "\n",
        "# Function to extract date from text\n",
        "def extract_date(text):\n",
        "    for pattern in DATE_PATTERNS:\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            groups = match.groups()\n",
        "            if len(groups) == 4:\n",
        "                # Case: 21st June 2024 or June 21st 2024\n",
        "                if groups[0].isdigit():  # 21st June 2024\n",
        "                    day = int(groups[0])\n",
        "                    month = MONTHS[groups[2].lower()]\n",
        "                    year = int(groups[3])\n",
        "                else:  # June 21st 2024\n",
        "                    day = int(groups[1])\n",
        "                    month = MONTHS[groups[0].lower()]\n",
        "                    year = int(groups[3])\n",
        "            elif len(groups) == 3:\n",
        "                # Case: 21/06/2024 or 21-06-2024\n",
        "                day = int(groups[0])\n",
        "                month = int(groups[1])\n",
        "                year = int(groups[2])\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            return f\"{day:02d}/{int(month):02d}/{year}\"\n",
        "    return \"Date not found\"\n",
        "\n",
        "# Function to read CSV and apply date parsing\n",
        "def process_csv(file_path):\n",
        "    with open(file_path, newline='') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        headers = reader.fieldnames\n",
        "        text_column = headers[0]  # Assume first column is the text column\n",
        "        for row in reader:\n",
        "            text = row[text_column]\n",
        "            extracted = extract_date(text)\n",
        "            print(f\"Text: {text}\")\n",
        "            print(f\"Extracted Date: {extracted}\\n\")\n",
        "\n",
        "# Run the parser\n",
        "process_csv(\"date_parser_testcases.csv\")"
      ],
      "metadata": {
        "id": "kkLJ_T0lRaxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b34f96-b5c9-4305-bbdd-20a338a19a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: The event will take place on March 5, 2023.\n",
            "Extracted Date: 05/03/2023\n",
            "\n",
            "Text: Her birthday is on 07/08/1990.\n",
            "Extracted Date: 07/08/1990\n",
            "\n",
            "Text: The deadline is 2022-12-31.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: We met on 1st of January 2000.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The concert is scheduled for 15th September, 2021.\n",
            "Extracted Date: 15/09/2021\n",
            "\n",
            "Text: Let's catch up on 02.04.2022.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The project started on 5/6/19.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: He was born on 1987/11/23.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: Christmas is on 25th Dec 2024.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The meeting is set for April 03, 2020.\n",
            "Extracted Date: 03/04/2020\n",
            "\n",
            "Text: Her birthdate, noted as 1997-05-20, is in the records.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: Her appointment is on the 2nd of March, 2021.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The exam date is 2021.11.10.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: They got married on 12/12/12.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The workshop is on February 15th, 2022.\n",
            "Extracted Date: 15/02/2022\n",
            "\n",
            "Text: Submit your report by 08/31/2021.\n",
            "Extracted Date: 08/31/2021\n",
            "\n",
            "Text: The course starts on 1st July 2023.\n",
            "Extracted Date: 01/07/2023\n",
            "\n",
            "Text: Independence Day is on 4th of July, 2022.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: His birthday is 1995/10/30.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The new year begins on 01-01-2023.\n",
            "Extracted Date: 01/01/2023\n",
            "\n",
            "Text: The seminar is on 03/14/2022.\n",
            "Extracted Date: 03/14/2022\n",
            "\n",
            "Text: My last day is 31.08.2020.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The due date is 2020-02-28.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The holiday starts on Dec 20th, 2021.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The conference will be held on 5th May 2023.\n",
            "Extracted Date: 05/05/2023\n",
            "\n",
            "Text: They moved in on 12/25/2019.\n",
            "Extracted Date: 12/25/2019\n",
            "\n",
            "Text: The festival begins on March 17, 2022.\n",
            "Extracted Date: 17/03/2022\n",
            "\n",
            "Text: The ceremony is on 11.11.2021.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The event is on 2023/07/04.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: Her graduation is on May 30th, 2022.\n",
            "Extracted Date: 30/05/2022\n",
            "\n",
            "Text: The release date is 2021-09-09.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The interview is on 1/2/2022.\n",
            "Extracted Date: 01/02/2022\n",
            "\n",
            "Text: The celebration is on 2022-10-10.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: His wedding is on 6th of August, 2020.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: She was born on 3rd March 1998.\n",
            "Extracted Date: 03/03/1998\n",
            "\n",
            "Text: The opening is on 10/10/2018.\n",
            "Extracted Date: 10/10/2018\n",
            "\n",
            "Text: The deadline is 2020.12.15.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The party is on 31-12-2022.\n",
            "Extracted Date: 31/12/2022\n",
            "\n",
            "Text: The workshop is on February 29, 2024.\n",
            "Extracted Date: 29/02/2024\n",
            "\n",
            "Text: Vacation starts on 07/15/2021.\n",
            "Extracted Date: 07/15/2021\n",
            "\n",
            "Text: The application is due by 2022-03-03.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The tournament is on June 1st, 2021.\n",
            "Extracted Date: 01/06/2021\n",
            "\n",
            "Text: The closing date is 08/08/2020.\n",
            "Extracted Date: 08/08/2020\n",
            "\n",
            "Text: The concert is on 2020/09/09.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The exam is on 01.01.2022.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: Independence Day is 2023-07-04.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The last date is 30th November 2022.\n",
            "Extracted Date: 30/11/2022\n",
            "\n",
            "Text: The conference is on 15th October 2023.\n",
            "Extracted Date: 15/10/2023\n",
            "\n",
            "Text: His birthdate is 1990-05-20.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The festival is on 12th August 2024.\n",
            "Extracted Date: 12/08/2024\n",
            "\n",
            "Text: Input\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: We are planning to meet on March 5, 2023, for lunch.\n",
            "Extracted Date: 05/03/2023\n",
            "\n",
            "Text: Her birthday, which she celebrates on 07/08/1990, is coming up soon.\n",
            "Extracted Date: 07/08/1990\n",
            "\n",
            "Text: The deadline, unfortunately, is set to 2022-12-31.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: We first met on the 1st of January 2000 at the conference.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The concert, happening on 15th September 2021, will be amazing.\n",
            "Extracted Date: 15/09/2021\n",
            "\n",
            "Text: Remember, the meeting is on 02.04.2022 at 10 AM.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: Let's wrap up the project by 5/6/19, so we can relax.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: His birth date, recorded as 1987/11/23, was a memorable day.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: We celebrate Christmas every year on 25th Dec, including 2024.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The meeting is rescheduled to April 03, 2020, as per the latest update.\n",
            "Extracted Date: 03/04/2020\n",
            "\n",
            "Text: Their anniversary is marked on the 2nd of March, 2021.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The official exam date is now 2021.11.10, per the new schedule.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: They celebrated their wedding on 12/12/12 in grand style.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: Our next workshop is scheduled for February 15th, 2022.\n",
            "Extracted Date: 15/02/2022\n",
            "\n",
            "Text: The submission deadline, noted as 08/31/2021, is fast approaching.\n",
            "Extracted Date: 08/31/2021\n",
            "\n",
            "Text: The course officially begins on 1st July 2023.\n",
            "Extracted Date: 01/07/2023\n",
            "\n",
            "Text: We celebrate Independence Day on the 4th of July every year, including 2022.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: He mentioned that his birth date is 1995/10/30 in the form.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The new year's celebration begins on 01-01-2023 at midnight.\n",
            "Extracted Date: 01/01/2023\n",
            "\n",
            "Text: We scheduled the seminar for 03/14/2022, don't forget.\n",
            "Extracted Date: 03/14/2022\n",
            "\n",
            "Text: My final working day here is noted as 31.08.2020.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The project's due date is officially 2020-02-28.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The holiday vacation starts on Dec 20th, 2021, for everyone.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The conference, marked for 5th May 2023, is a significant event.\n",
            "Extracted Date: 05/05/2023\n",
            "\n",
            "Text: They officially moved in on 12/25/2019.\n",
            "Extracted Date: 12/25/2019\n",
            "\n",
            "Text: Our festival starts on March 17, 2022, with a parade.\n",
            "Extracted Date: 17/03/2022\n",
            "\n",
            "Text: The ceremony date is fixed as 11.11.2021.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The big event is planned for 2023/07/04, so mark your calendars.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: Her graduation day is set for May 30th, 2022.\n",
            "Extracted Date: 30/05/2022\n",
            "\n",
            "Text: The software release date is set for 2021-09-09.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The job interview is on 1/2/2022, don't be late.\n",
            "Extracted Date: 01/02/2022\n",
            "\n",
            "Text: The grand celebration is on 2022-10-10, a date to remember.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The wedding is on 6th of August, 2020, in the evening.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: She mentioned she was born on the 3rd of March 1998.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The official opening date is 10/10/2018, as per the announcement.\n",
            "Extracted Date: 10/10/2018\n",
            "\n",
            "Text: The critical deadline is 2020.12.15, please note it.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The New Year's Eve party is on 31-12-2022, join us!\n",
            "Extracted Date: 31/12/2022\n",
            "\n",
            "Text: The next workshop is on February 29, 2024, due to the leap year.\n",
            "Extracted Date: 29/02/2024\n",
            "\n",
            "Text: Vacation officially starts on 07/15/2021, get ready.\n",
            "Extracted Date: 07/15/2021\n",
            "\n",
            "Text: The application submission date is 2022-03-03.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The tournament begins on June 1st, 2021, early in the morning.\n",
            "Extracted Date: 01/06/2021\n",
            "\n",
            "Text: The registration closing date is 08/08/2020.\n",
            "Extracted Date: 08/08/2020\n",
            "\n",
            "Text: The music concert is scheduled for 2020/09/09.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The exam will be held on 01.01.2022, start preparing.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: We celebrate Independence Day on 2023-07-04, as always.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The final date for submission is 30th November 2022.\n",
            "Extracted Date: 30/11/2022\n",
            "\n",
            "Text: The annual conference is on 15th October 2023, mark your calendars.\n",
            "Extracted Date: 15/10/2023\n",
            "\n",
            "Text: His birthdate, noted as 1990-05-20, is in the records.\n",
            "Extracted Date: Date not found\n",
            "\n",
            "Text: The festival will be celebrated on 12th August 2024, with grand events.\n",
            "Extracted Date: 12/08/2024\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part3**"
      ],
      "metadata": {
        "id": "zyMAzGtYmmGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "# Pronoun mapping dictionaries\n",
        "male_to_female = {\n",
        "    \"he\": \"she\",\n",
        "    \"him\": \"her\",\n",
        "    \"his\": \"her\",\n",
        "    \"himself\": \"herself\"\n",
        "}\n",
        "\n",
        "female_to_male = {\n",
        "    \"she\": \"he\",\n",
        "    \"her\": \"him\",\n",
        "    \"hers\": \"his\",\n",
        "    \"herself\": \"himself\"\n",
        "}\n",
        "\n",
        "# Words suggesting \"her\" is possessive\n",
        "possessive_contexts = [\"book\", \"car\", \"bag\", \"pen\", \"idea\", \"dog\", \"phone\", \"shoes\", \"attitude\", \"trip\", \"laptop\"]\n",
        "\n",
        "def is_possessive(word, next_word):\n",
        "    return next_word and next_word.lower() in possessive_contexts\n",
        "\n",
        "# Main transformation function\n",
        "def transform_sentence(sentence, target_gender):\n",
        "    words = sentence.split()\n",
        "    transformed = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(words):\n",
        "        word = words[i]\n",
        "        stripped = re.sub(r'[^\\w]', '', word)\n",
        "        punct = word[len(stripped):] if len(stripped) < len(word) else ''\n",
        "\n",
        "        lower = stripped.lower()\n",
        "        next_word = words[i + 1] if i + 1 < len(words) else \"\"\n",
        "\n",
        "        # Use correct mapping\n",
        "        if target_gender == \"female\" and lower in male_to_female:\n",
        "            if lower == \"his\":\n",
        "                replacement = \"her\"\n",
        "            else:\n",
        "                replacement = male_to_female[lower]\n",
        "        elif target_gender == \"male\" and lower in female_to_male:\n",
        "            if lower == \"her\":\n",
        "                replacement = \"his\" if is_possessive(lower, next_word) else \"him\"\n",
        "            else:\n",
        "                replacement = female_to_male[lower]\n",
        "        else:\n",
        "            replacement = stripped\n",
        "\n",
        "        # Preserve case\n",
        "        if stripped.istitle():\n",
        "            replacement = replacement.capitalize()\n",
        "        elif stripped.isupper():\n",
        "            replacement = replacement.upper()\n",
        "\n",
        "        transformed.append(replacement + punct)\n",
        "        i += 1\n",
        "\n",
        "    return ' '.join(transformed)\n",
        "\n",
        "# Process CSV and check accuracy\n",
        "def process_pronoun_csv(filepath):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            input_text = row['input_text']\n",
        "            target_gender = row['target_gender'].strip().lower()\n",
        "            expected = row['expected_output'].strip()\n",
        "\n",
        "            output = transform_sentence(input_text, target_gender).strip()\n",
        "\n",
        "            match = output.strip().lower() == expected.strip().lower()\n",
        "            print(f\"Input:    {input_text}\")\n",
        "            print(f\"Gender:   {target_gender}\")\n",
        "            print(f\"Output:   {output}\")\n",
        "            print(f\"Expected: {expected}\")\n",
        "            print(f\"Match:    {match}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            if match:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "    print(f\"\\n✅ Accuracy: {correct}/{total} correct ({(correct / total) * 100:.2f}%)\")\n",
        "\n",
        "# Run\n",
        "process_pronoun_csv(\"pronoun_testcases.csv\")"
      ],
      "metadata": {
        "id": "Qymph60sRa0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0309c278-dfea-44a4-9e22-6dce87c6d88c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:    He is going to the market.\n",
            "Gender:   female\n",
            "Output:   She is going to the market.\n",
            "Expected: She is going to the market.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    His book is on the table.\n",
            "Gender:   female\n",
            "Output:   Her book is on the table.\n",
            "Expected: Her book is on the table.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    I saw him yesterday.\n",
            "Gender:   female\n",
            "Output:   I saw her yesterday.\n",
            "Expected: I saw her yesterday.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    He hurt himself.\n",
            "Gender:   female\n",
            "Output:   She hurt herself.\n",
            "Expected: She hurt herself.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    I called him last night.\n",
            "Gender:   female\n",
            "Output:   I called her last night.\n",
            "Expected: I called her last night.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    That is his car.\n",
            "Gender:   female\n",
            "Output:   That is her car.\n",
            "Expected: That is her car.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    He told me about his trip.\n",
            "Gender:   female\n",
            "Output:   She told me about her trip.\n",
            "Expected: She told me about her trip.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    The teacher gave him a warning.\n",
            "Gender:   female\n",
            "Output:   The teacher gave her a warning.\n",
            "Expected: The teacher gave her a warning.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    He blames himself for the mistake.\n",
            "Gender:   female\n",
            "Output:   She blames herself for the mistake.\n",
            "Expected: She blames herself for the mistake.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    He brought his laptop.\n",
            "Gender:   female\n",
            "Output:   She brought her laptop.\n",
            "Expected: She brought her laptop.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    He made it himself.\n",
            "Gender:   female\n",
            "Output:   She made it herself.\n",
            "Expected: She made it herself.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    I don’t like his attitude.\n",
            "Gender:   female\n",
            "Output:   I dontt like her attitude.\n",
            "Expected: I don’t like her attitude.\n",
            "Match:    False\n",
            "--------------------------------------------------\n",
            "Input:    Tell him to come here.\n",
            "Gender:   female\n",
            "Output:   Tell her to come here.\n",
            "Expected: Tell her to come here.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    She is going to the market.\n",
            "Gender:   male\n",
            "Output:   He is going to the market.\n",
            "Expected: He is going to the market.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    Her book is on the table.\n",
            "Gender:   male\n",
            "Output:   His book is on the table.\n",
            "Expected: His book is on the table.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    I saw her yesterday.\n",
            "Gender:   male\n",
            "Output:   I saw him yesterday.\n",
            "Expected: I saw him yesterday.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    She hurt herself.\n",
            "Gender:   male\n",
            "Output:   He hurt himself.\n",
            "Expected: He hurt himself.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    I called her last night.\n",
            "Gender:   male\n",
            "Output:   I called him last night.\n",
            "Expected: I called him last night.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    That is her car.\n",
            "Gender:   male\n",
            "Output:   That is him car.\n",
            "Expected: That is his car.\n",
            "Match:    False\n",
            "--------------------------------------------------\n",
            "Input:    She told me about her trip.\n",
            "Gender:   male\n",
            "Output:   He told me about him trip.\n",
            "Expected: He told me about his trip.\n",
            "Match:    False\n",
            "--------------------------------------------------\n",
            "Input:    The teacher gave her a warning.\n",
            "Gender:   male\n",
            "Output:   The teacher gave him a warning.\n",
            "Expected: The teacher gave him a warning.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    She blames herself for the mistake.\n",
            "Gender:   male\n",
            "Output:   He blames himself for the mistake.\n",
            "Expected: He blames himself for the mistake.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    She brought her laptop.\n",
            "Gender:   male\n",
            "Output:   He brought him laptop.\n",
            "Expected: He brought his laptop.\n",
            "Match:    False\n",
            "--------------------------------------------------\n",
            "Input:    She made it herself.\n",
            "Gender:   male\n",
            "Output:   He made it himself.\n",
            "Expected: He made it himself.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "Input:    I don’t like her attitude.\n",
            "Gender:   male\n",
            "Output:   I dontt like him attitude.\n",
            "Expected: I don’t like his attitude.\n",
            "Match:    False\n",
            "--------------------------------------------------\n",
            "Input:    Tell her to come here.\n",
            "Gender:   male\n",
            "Output:   Tell him to come here.\n",
            "Expected: Tell him to come here.\n",
            "Match:    True\n",
            "--------------------------------------------------\n",
            "\n",
            "✅ Accuracy: 21/26 correct (80.77%)\n"
          ]
        }
      ]
    }
  ]
}